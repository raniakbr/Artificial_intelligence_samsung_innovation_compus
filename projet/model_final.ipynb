{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import imageai\r\n",
    "import tensorflow as tf\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tf.config.run_functions_eagerly(True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\r\n",
    "trainer = DetectionModelTrainer()\r\n",
    "trainer.setModelTypeAsYOLOv3()\r\n",
    "\r\n",
    "trainer.setDataDirectory(\"final_model\")\r\n",
    "trainer.setTrainConfig(object_names_array=['house', 'person', 'tree', 'flower', 'sun', 'knife', 'hammer', 'scissors',\r\n",
    "                       'rocket', 'rifle', 'rainbow'], batch_size=10, num_experiments=1, train_from_pretrained_model=\"pretrained-yolov3.h5\")\r\n",
    "trainer.trainModel()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "Average IOU for 9 anchors: 0.75\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  final_model\\json\\detection_config.json\n",
      "Training on: \t['flower', 'hammer', 'house', 'knife', 'person', 'rainbow', 'rifle', 'rocket', 'scissors', 'sun', 'tree']\n",
      "Training with Batch Size:  10\n",
      "Number of Experiments:  1\n",
      "Training with transfer learning from pretrained Model\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Rania\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Rania\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1969: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Rania\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4211: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Rania\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "912/912 [==============================] - 31280s 34s/step - loss: 31.8822 - yolo_layer_loss: 5.2008 - yolo_layer_1_loss: 8.1949 - yolo_layer_2_loss: 18.4866 - val_loss: 13.9673 - val_yolo_layer_loss: 1.1831 - val_yolo_layer_1_loss: 4.2096 - val_yolo_layer_2_loss: 8.5746\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\r\n",
    "\r\n",
    "trainer = DetectionModelTrainer()\r\n",
    "trainer.setModelTypeAsYOLOv3()\r\n",
    "trainer.setDataDirectory(data_directory=\"final_model\")\r\n",
    "metrics = trainer.evaluateModel(model_path=\"./final_model/models\", json_path=\"./final_model/json/detection_config.json\",\r\n",
    "                                iou_threshold=0.2, object_threshold=0.2, nms_threshold=0.2)\r\n",
    "print(metrics)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Model evaluation....\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Rania\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  ./final_model/models\\detection_model-ex-001--loss-0031.882.h5 \n",
      "\n",
      "Using IoU :  0.2\n",
      "Using Object Threshold :  0.2\n",
      "Using Non-Maximum Suppression :  0.2\n",
      "flower: 0.4009\n",
      "hammer: 0.0000\n",
      "house: 0.8123\n",
      "knife: 0.0818\n",
      "person: 0.7726\n",
      "rainbow: 0.0000\n",
      "rifle: 0.5921\n",
      "rocket: 0.2459\n",
      "scissors: 0.0000\n",
      "sun: 0.7487\n",
      "tree: 0.1388\n",
      "mAP: 0.3448\n",
      "===============================\n",
      "[{'model_file': './final_model/models\\\\detection_model-ex-001--loss-0031.882.h5', 'using_iou': 0.2, 'using_object_threshold': 0.2, 'using_non_maximum_suppression': 0.2, 'average_precision': {'flower': 0.4008512353302792, 'hammer': 0, 'house': 0.8123436306340719, 'knife': 0.0818181818181818, 'person': 0.7726360331836617, 'rainbow': 0.0, 'rifle': 0.5921257391845627, 'rocket': 0.24586206896551724, 'scissors': 0, 'sun': 0.7486573576799141, 'tree': 0.13877314814814815}, 'map': 0.3448243086313033}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from imageai.Detection.Custom import CustomObjectDetection\r\n",
    "detector = CustomObjectDetection()\r\n",
    "detector.setModelTypeAsYOLOv3()\r\n",
    "detector.setModelPath(\r\n",
    "    \"./final_model/models/detection_model-ex-001--loss-0031.882.h5\")\r\n",
    "detector.setJsonPath(\"./final_model/json/detection_config.json\")\r\n",
    "detector.loadModel()\r\n",
    "detections = detector.detectObjectsFromImage(\r\n",
    "    input_image=\"47.jpg\", output_image_path=\"test_res.jpg\", minimum_percentage_probability=80)\r\n",
    "for detection in detections:\r\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[341, 193, 424, 371]\n",
      "[438, 208, 521, 357]\n",
      "[441, 215, 517, 364]\n",
      "[182, 230, 247, 431]\n",
      "person  :  98.76635670661926  :  [341, 193, 424, 371]\n",
      "person  :  97.50291109085083  :  [438, 208, 521, 357]\n",
      "tree  :  82.70829319953918  :  [441, 215, 517, 364]\n",
      "person  :  96.01204991340637  :  [182, 230, 247, 431]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "#From the results of the object detecion model, we create a dataframe that contains the boxpoints of each object on the image (house, tree and person)\r\n",
    "df = pd.DataFrame({'name': pd.Series(dtype='str'),\r\n",
    "                   'xmin': pd.Series(dtype='int'),\r\n",
    "                   'ymin': pd.Series(dtype='int'),\r\n",
    "                   'xmax': pd.Series(dtype='int'),\r\n",
    "                   'ymax': pd.Series(dtype='int'),\r\n",
    "                   })\r\n",
    "for detection in detections:\r\n",
    "  new_row= pd.DataFrame()\r\n",
    "  new_row = pd.DataFrame([[detection['name'],detection[\"box_points\"][0],detection[\"box_points\"][1],detection[\"box_points\"][2],detection[\"box_points\"][3]]],columns=['name','xmin','ymin','xmax','ymax'])\r\n",
    "  df = pd.concat([df, new_row], ignore_index=True)\r\n",
    "#We add three more columns that contains heights, widths and areas of the objects  \r\n",
    "df['height'] = df['xmax']-df['xmin']\r\n",
    "df['width'] = df['ymax']-df['ymin']\r\n",
    "df['area'] = df['height']*df['width']\r\n",
    "\r\n",
    "#We create another dataframe that contains the thresholds of height, width and area for each object, so we can make the interpretation  \r\n",
    "thresholds = pd.DataFrame({'object': ['house', 'tree', 'person'], 'height': [(\r\n",
    "    size[0]*30/100, size[0]*60/100), (size[0]*30/100, size[0]*80/100), ((size[0]*30/100, size[0]*40/100))], 'width': [(size[0]*30/100), (size[0]*5/100), (size[0]*5/100)], 'area': [(0), (0), (0)]})\r\n",
    "thresholds.set_index('object',inplace=True)\r\n",
    "# TO FILL ....\r\n",
    "\r\n",
    "#After that, we create a function that takes as input the object that we want to analyse (measure the proportions), and then return the interpretation based on the height, width and area (for the moment, we only check the height of the objects) \r\n",
    "def interpretation(drawing,df) : #drawing is the object we want to check its proportions, and df is the dataframe that contains the informations of each object (for example: interpretation('house',df))\r\n",
    "  interpretation = 'the size of the object'+' \\\"'+drawing +'\\\"'+' is normal'\r\n",
    "  if drawing == 'tree' : \r\n",
    "    if int(df[df['name'] == drawing].height) < thresholds['height'][drawing][0] : \r\n",
    "      interpretation = 'The size of the tree in the drawing is very small, it relates to a weak ego'\r\n",
    "    elif int(df[df['name'] == drawing].height) > thresholds['height'][drawing][1]:\r\n",
    "      interpretation = 'The size of the tree in the drawing is very big, it relates to a strong inner stength and ego'\r\n",
    "  \r\n",
    "  elif drawing == 'house' : \r\n",
    "    if int(df[df['name'] == drawing].height) < thresholds['height'][drawing][0]:\r\n",
    "      interpretation = 'The height of the house in the drawing is very small, it signifies rejection of the home and family life'\r\n",
    "    elif int(df[df['name'] == drawing].height) > thresholds['height'][drawing][1]:\r\n",
    "      interpretation = 'The height of the house in the drawing is very big, it signifies the view of the home as restrictive and controlling'\r\n",
    "  \r\n",
    "  elif drawing == 'person' : \r\n",
    "    if int(df[df['name'] == drawing].height) < thresholds['height'][drawing][0]:\r\n",
    "      interpretation = 'The height of the person in the drawing is very small, it reflects feeling of inferiority and insignificance'\r\n",
    "    elif int(df[df['name'] == drawing].height) > thresholds['height'][drawing][1]:\r\n",
    "      interpretation = 'The height of the person in the drawing is extremly large, it tell us that the patient has a high-level of self esteem, or may suffer from delusions of grandeur'\r\n",
    "      \r\n",
    "  else : \r\n",
    "    return 'no drawing found'\r\n",
    "\r\n",
    "  return interpretation #If interpretation == '', it means that we can tell anything about the sizes of the objects (the objects are in a normal size)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#After that, we crop the object we want to analyze on the image, using these two functions (the house object)\r\n",
    "# FUNCTIONS \r\n",
    "def boxpoints_object(ob,df) : #df is the dataframe that contains the informations about each object, and ob is the object we want to crop (for the moment, we only analyze the house) \r\n",
    "  if ob not in ['house','tree','person'] :\r\n",
    "    print('no object found')\r\n",
    "  else : \r\n",
    "    coordinates_obj = df[df.name==ob][['xmin','ymin','xmax','ymax']]\r\n",
    "    if coordinates_obj.shape[0] != 1 :\r\n",
    "      print('Error, the model detected zero or more than one',ob,'object' )\r\n",
    "      return 0\r\n",
    "    else : \r\n",
    "      coordinates_obj=coordinates_obj.values.flatten().tolist()\r\n",
    "      return [coordinates_obj[0], coordinates_obj[1], coordinates_obj[2], coordinates_obj[3]] \r\n",
    "\r\n",
    "#If the function returns 0, it means the presence of zero or more than one same object in the dataframe (for example: the dataset contains two house objects, or zero house object)\r\n",
    "\r\n",
    "def return_cropped_image(im,boxpoints) : #this function takes as input the original image, and then return the cropped image using the boxpoints returned by 'boxpoints_object' function  \r\n",
    "  im_cropped = im.crop((boxpoints_house))\r\n",
    "  im_cropped = im_cropped.resize((512,512))\r\n",
    "  return im_cropped\r\n",
    "\r\n",
    "#The cropped image (of the house) is then fed to the next model for further analysis (hassan's model)\r\n",
    "#ICI \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "print(df)\r\n",
    "print(interpretation('house', df))\r\n",
    "print(interpretation('tree', df))\r\n",
    "print(interpretation('person', df))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     name  xmin  ymin  xmax  ymax  height  width    area\n",
      "0     sun     0     8   206   161     206    153   31518\n",
      "1    tree   162    59   440   610     278    551  153178\n",
      "2   house   482   214   856   601     374    387  144738\n",
      "3  person   345   335   485   692     140    357   49980\n",
      "the size of the object \"house\" is normal\n",
      "the size of the object \"tree\" is normal\n",
      "The height of the person in the drawing is very small, it reflects feeling of inferiority and insignificance\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "b3ed8e708b643839dc49c9e4479760f0fed46f4af64d471bc476f8b8b680b9fd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}